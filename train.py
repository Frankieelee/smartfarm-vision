"""
YOLO11 è®­ç»ƒè„šæœ¬ - é’ˆå¯¹å¯†é›†å°ç›®æ ‡ä¼˜åŒ–
æ”¯æŒæ ‡å‡†æ¨¡å‹å’ŒCBAMæ³¨æ„åŠ›å¢å¼º
"""

from ultralytics import YOLO
import os
import sys
from datetime import datetime
from pathlib import Path
import torch
from train_strategy import *

os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'

# ============================================================
# æ—¥å¿—ä¿å­˜å·¥å…·ç±»
# ============================================================

class Logger:
    """åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶çš„æ—¥å¿—å·¥å…·"""
    def __init__(self, log_file):
        self.terminal = sys.stdout
        self.log_file = open(log_file, 'w', encoding='utf-8')
        
    def write(self, message):
        self.terminal.write(message)
        self.log_file.write(message)
        self.log_file.flush()  # å®æ—¶å†™å…¥æ–‡ä»¶
        
    def flush(self):
        self.terminal.flush()
        self.log_file.flush()




# ============================================================
# ğŸ”§ å·¥å…·å‡½æ•°
# ============================================================

def freeze_layers(model, freeze_config):
    """
    å†»ç»“æ¨¡å‹çš„æŒ‡å®šå±‚ï¼Œåªè®­ç»ƒ detection head
    
    Args:
        model: YOLO æ¨¡å‹å®ä¾‹
        freeze_config: å†»ç»“é…ç½®å­—å…¸
    
    Returns:
        tuple: (å†»ç»“çš„å‚æ•°æ•°é‡, å¯è®­ç»ƒçš„å‚æ•°æ•°é‡)
    """
    if not freeze_config.get('freeze_backbone', False):
        print("âš ï¸  æœªå¯ç”¨ backbone å†»ç»“ï¼Œæ‰€æœ‰å±‚éƒ½å°†è®­ç»ƒ")
        return 0, sum(p.numel() for p in model.model.parameters() if p.requires_grad)
    
    freeze_layers_list = freeze_config.get('freeze_layers', 10)
    
    # å¦‚æœæ˜¯æ•°å­—ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
    if isinstance(freeze_layers_list, int):
        freeze_layers_list = list(range(freeze_layers_list))
    
    print(f"\n{'='*60}")
    print(f"â„ï¸  å†»ç»“ Backbone é…ç½®")
    print(f"{'='*60}")
    print(f"ğŸ”’ å°†å†»ç»“å‰ {len(freeze_layers_list)} å±‚")
    
    # è·å–æ¨¡å‹çš„æ‰€æœ‰å±‚
    total_layers = len(list(model.model.model))
    print(f"ğŸ“Š æ¨¡å‹æ€»å±‚æ•°: {total_layers}")
    print(f"ğŸ¯ å†»ç»“å±‚: {freeze_layers_list}")
    print(f"ğŸ”¥ å¯è®­ç»ƒå±‚: {list(range(max(freeze_layers_list) + 1, total_layers))}")
    
    # å†»ç»“æŒ‡å®šå±‚
    frozen_params = 0
    trainable_params = 0
    
    for idx, (name, module) in enumerate(model.model.model.named_children()):
        if idx in freeze_layers_list:
            # å†»ç»“è¯¥å±‚çš„æ‰€æœ‰å‚æ•°
            for param in module.parameters():
                param.requires_grad = False
                frozen_params += param.numel()
            print(f"   â„ï¸  å±‚ {idx:2d} ({name:15s}): å·²å†»ç»“ ({sum(p.numel() for p in module.parameters()):,} å‚æ•°)")
        else:
            # ä¿æŒè¯¥å±‚å¯è®­ç»ƒ
            for param in module.parameters():
                param.requires_grad = True
                trainable_params += param.numel()
            print(f"   ğŸ”¥ å±‚ {idx:2d} ({name:15s}): å¯è®­ç»ƒ ({sum(p.numel() for p in module.parameters()):,} å‚æ•°)")
    
    print(f"\nğŸ“Š å‚æ•°ç»Ÿè®¡:")
    print(f"   â„ï¸  å†»ç»“å‚æ•°: {frozen_params:,} ({frozen_params / (frozen_params + trainable_params) * 100:.1f}%)")
    print(f"   ğŸ”¥ å¯è®­ç»ƒå‚æ•°: {trainable_params:,} ({trainable_params / (frozen_params + trainable_params) * 100:.1f}%)")
    print(f"{'='*60}\n")
    
    return frozen_params, trainable_params


# ============================================================
# è®­ç»ƒä»£ç ï¼ˆä¸ç”¨ä¿®æ”¹ï¼‰
# ============================================================

if __name__ == '__main__':
    # ========== æ˜¾ç¤ºé…ç½®ä¿¡æ¯ ==========
    print("="*60)
    print("ğŸš€ YOLOè®­ç»ƒé…ç½®")
    print("="*60)
    
    # æ˜¾ç¤ºå†»ç»“çŠ¶æ€
    if FREEZE_CONFIG.get('freeze_backbone', False):
        freeze_layers_count = FREEZE_CONFIG.get('freeze_layers', 10)
        if isinstance(freeze_layers_count, int):
            print(f"â„ï¸  Backbone å†»ç»“: å¯ç”¨ (å‰ {freeze_layers_count} å±‚)")
        else:
            print(f"â„ï¸  Backbone å†»ç»“: å¯ç”¨ (å…± {len(freeze_layers_count)} å±‚)")
    else:
        print(f"ğŸ”¥ Backbone å†»ç»“: ç¦ç”¨ (å…¨é‡è®­ç»ƒ)")
    
    print(f"ğŸ“Š æ•°æ®å¢å¼ºæ–¹æ¡ˆ: {SELECTED_AUGMENTATION.upper()}")
    
    # é‡æ–°è·å–è®­ç»ƒå‚æ•°ï¼ˆç¡®ä¿ä½¿ç”¨æœ€æ–°é…ç½®ï¼‰
    TRAIN_ARGS = get_train_args()
    
    print("-"*60)
    
    model_path = MODEL_CONFIG['path']
    model_type = MODEL_CONFIG['type']
    
    # ========== æ¨¡å¼1ï¸âƒ£: ä»å¤´è®­ç»ƒï¼ˆéšæœºåˆå§‹åŒ–ï¼‰ ==========
    if model_type == 'scratch':
        print(f"ğŸ“¦ æ¨¡å‹ç±»å‹: ä»å¤´è®­ç»ƒ")
        print(f"ğŸ“ æ¶æ„æ–‡ä»¶: {model_path}")
        print(f"ğŸ² æƒé‡åˆå§‹åŒ–: éšæœº")
        
        model = YOLO(model_path)
        model_name = Path(model_path).stem
        
    # ========== æ¨¡å¼2ï¸âƒ£: ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ ==========
    elif model_type == 'pretrained':
        print(f"ğŸ“¦ æ¨¡å‹ç±»å‹: é¢„è®­ç»ƒæ¨¡å‹")
        print(f"ğŸ“ æ¨¡å‹æ–‡ä»¶: {model_path}")
        print(f"âœ… æƒé‡æ¥æº: å®˜æ–¹/å·²è®­ç»ƒæƒé‡")
        
        model = YOLO(model_path)
        model_name = Path(model_path).stem
        
    # ========== æ¨¡å¼3ï¸âƒ£: è‡ªå®šä¹‰æ¶æ„ + è¿ç§»å­¦ä¹  ==========
    elif model_type == 'custom':
        print(f"ğŸ“¦ æ¨¡å‹ç±»å‹: è‡ªå®šä¹‰æ¶æ„ + è¿ç§»å­¦ä¹ ")
        print(f"ğŸ“ æ¶æ„æ–‡ä»¶: {model_path}")
        
        model = YOLO(model_path)
        model_name = Path(model_path).stem
        
        # åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if MODEL_CONFIG.get('pretrained'):
            pretrained_path = MODEL_CONFIG['pretrained']
            
            if os.path.exists(pretrained_path):
                print(f"ğŸ“¥ é¢„è®­ç»ƒæƒé‡: {pretrained_path}")
                
                try:
                    # åŠ è½½checkpoint
                    pretrained = torch.load(pretrained_path, map_location='cpu', weights_only=False)
                    
                    # éªŒè¯åŠ è½½æ˜¯å¦æˆåŠŸ
                    if pretrained is None:
                        raise ValueError("æƒé‡æ–‡ä»¶ä¸ºç©ºæˆ–æŸå")
                    
                    # æå– state_dictï¼ˆå¤„ç†ä¸åŒæ ¼å¼ï¼‰
                    if isinstance(pretrained, dict):
                        if 'model' in pretrained:
                            # Ultralyticsæ ¼å¼ï¼š{'model': model_object, 'optimizer': ...}
                            pretrained_state = pretrained['model'].state_dict()
                        elif 'state_dict' in pretrained:
                            # æ ‡å‡†æ ¼å¼ï¼š{'state_dict': {...}, ...}
                            pretrained_state = pretrained['state_dict']
                        else:
                            # ç›´æ¥æ˜¯ state_dict
                            pretrained_state = pretrained
                    elif hasattr(pretrained, 'state_dict'):
                        pretrained_state = pretrained.state_dict()
                    else:
                        raise ValueError("æ— æ³•ä»checkpointä¸­æå–state_dict")
                    
                    model_state = model.model.state_dict()
                    
                    # è¿‡æ»¤å…¼å®¹çš„æƒé‡
                    compatible_state = {}
                    for k, v in pretrained_state.items():
                        if k in model_state and model_state[k].shape == v.shape:
                            compatible_state[k] = v
                    
                    incompatible_count = len(pretrained_state) - len(compatible_state)
                    
                    # åŠ è½½æƒé‡
                    model.model.load_state_dict(compatible_state, strict=False)
                    
                    print(f"âœ… æˆåŠŸåŠ è½½ {len(compatible_state)}/{len(pretrained_state)} ä¸ªæƒé‡")
                    if incompatible_count > 0:
                        print(f"âš ï¸  è·³è¿‡ {incompatible_count} ä¸ªä¸å…¼å®¹æƒé‡ï¼ˆæ–°æ¨¡å—å°†éšæœºåˆå§‹åŒ–ï¼‰")
                    
                except Exception as e:
                    print(f"âŒ åŠ è½½æƒé‡å¤±è´¥: {e}")
                    print("   å°†ä»å¤´å¼€å§‹è®­ç»ƒï¼ˆéšæœºåˆå§‹åŒ–ï¼‰")
                    import traceback
                    traceback.print_exc()
            else:
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {pretrained_path}")
                print("   å°†ä»å¤´å¼€å§‹è®­ç»ƒï¼ˆéšæœºåˆå§‹åŒ–ï¼‰")
        else:
            print(f"âš ï¸  æœªæŒ‡å®šé¢„è®­ç»ƒæƒé‡ï¼Œå°†éšæœºåˆå§‹åŒ–")
    
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}ï¼Œè¯·ä½¿ç”¨ 'scratch', 'pretrained', 'custom'")
    
    # ========== å†»ç»“ Backboneï¼ˆå¦‚æœå¯ç”¨ï¼‰==========
    frozen_params, trainable_params = freeze_layers(model, FREEZE_CONFIG)
    
    # ========== ç”Ÿæˆå®éªŒåç§° ==========
    dataset_name = Path(DATA_PATH).parent.name
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # å¦‚æœå†»ç»“äº† backboneï¼Œåœ¨å®éªŒåç§°ä¸­æ ‡æ³¨
    freeze_suffix = ""
    if FREEZE_CONFIG.get('freeze_backbone', False):
        freeze_layers_count = FREEZE_CONFIG.get('freeze_layers', 10)
        if isinstance(freeze_layers_count, int):
            freeze_suffix = f"_freeze{freeze_layers_count}"
        else:
            freeze_suffix = f"_freeze{len(freeze_layers_count)}"
    
    experiment_name = f"{dataset_name}_{model_name}_{TRAIN_ARGS['imgsz']}{freeze_suffix}_{timestamp}"
    
    print(f"ğŸ“Š æ•°æ®é›†: {dataset_name}")
    print(f"ğŸ¯ å®éªŒåç§°: {experiment_name}")
    print(f"ğŸ“‚ ä¿å­˜è·¯å¾„: runs/train/{experiment_name}/")
    
    # æ˜¾ç¤ºå†»ç»“çŠ¶æ€
    if FREEZE_CONFIG.get('freeze_backbone', False):
        print(f"â„ï¸  Backbone çŠ¶æ€: å·²å†»ç»“ ({frozen_params:,} å‚æ•°)")
        print(f"ğŸ”¥ å¯è®­ç»ƒå‚æ•°: {trainable_params:,} å‚æ•°")
        print(f"ğŸ’¡ å»ºè®®: ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡ (å½“å‰: lr0={TRAIN_ARGS['lr0']})")
    else:
        print(f"ğŸ”¥ è®­ç»ƒæ¨¡å¼: å…¨éƒ¨å‚æ•°å¯è®­ç»ƒ")
    
    # ========== è®¾ç½®æ—¥å¿—ä¿å­˜ ==========
    original_stdout = sys.stdout
    log_file = None
    
    log_dir = Path('runs/train') / experiment_name
    log_dir.mkdir(parents=True, exist_ok=True)
    log_file = log_dir / 'training_log.txt'
    
    print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {log_file}")
    print("="*60 + "\n")
    
    # é‡å®šå‘è¾“å‡ºï¼ˆåŒæ—¶æ‰“å°åˆ°æ§åˆ¶å°å’Œæ–‡ä»¶ï¼‰
    sys.stdout = Logger(log_file)

    try:
        # ========== å¼€å§‹è®­ç»ƒ ==========
        results = model.train(
            data=DATA_PATH,
            project='runs/train',
            name=experiment_name,
            exist_ok=False,
            **TRAIN_ARGS  # å±•å¼€æ‰€æœ‰è®­ç»ƒå‚æ•°
        )

        # ========== è®­ç»ƒå®Œæˆåçš„ä¿¡æ¯ ==========
        output_dir = Path('runs/train') / experiment_name
        print("\n" + "=" * 60)
        print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
        print("=" * 60)
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}/")
        print(f"ğŸ† æœ€ä½³æƒé‡: {output_dir}/weights/best.pt")
        print(f"ğŸ“Š æœ€ç»ˆæƒé‡: {output_dir}/weights/last.pt")
        print(f"ğŸ“ˆ è®­ç»ƒæ›²çº¿: {output_dir}/results.png")
        print(f"ğŸ“‹ è®­ç»ƒæ—¥å¿—: {output_dir}/results.csv")
        print(f"ğŸ“ æ§åˆ¶å°æ—¥å¿—: {output_dir}/training_log.txt")
        print("-" * 60)
        print(f"ğŸ“Š æœ€ç»ˆ mAP50:    {results.results_dict['metrics/mAP50(B)']:.3f}")
        print(f"ğŸ“Š æœ€ç»ˆ mAP50-95: {results.results_dict['metrics/mAP50-95(B)']:.3f}")
        print("=" * 60)
        
    finally:
        # ç¡®ä¿æ¢å¤æ ‡å‡†è¾“å‡ºï¼ˆå³ä½¿å‡ºé”™ä¹Ÿä¼šæ‰§è¡Œï¼‰
        sys.stdout.log_file.close()
        sys.stdout = original_stdout
        print(f"\nâœ… æ—¥å¿—å·²ä¿å­˜åˆ°: {log_file}")
