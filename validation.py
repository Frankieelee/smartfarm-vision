"""
YOLO æ¨¡å‹éªŒè¯è„šæœ¬ - åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¯„ä¼°
æ”¯æŒï¼šè®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†çš„å®Œæ•´è¯„ä¼°
"""

from ultralytics import YOLO
from pathlib import Path
import pandas as pd
from datetime import datetime
import json

# ============================================================
# é…ç½®åŒºåŸŸ
# ============================================================

# æ¨¡å‹é…ç½®
MODEL_PATH = '/tmp/pycharm_project_990/runs/detect/runs/train/datasets_yolo11m_800_20260128_151115/weights/best.pt'

# æ•°æ®é›†é…ç½®ï¼ˆæ”¯æŒå¤šä¸ªæ•°æ®é›†ï¼‰
DATASETS = {
    'val': './datasets/data.yaml',        # éªŒè¯é›†ï¼ˆé»˜è®¤ï¼‰
    'train': './datasets/data.yaml',      # è®­ç»ƒé›†ï¼ˆæ£€æŸ¥è¿‡æ‹Ÿåˆï¼‰
    # 'test': './path/to/test/data.yaml', # æµ‹è¯•é›†ï¼ˆå¦‚æœæœ‰ï¼‰
}

# éªŒè¯å‚æ•°
VAL_ARGS = {
    'imgsz': 640,           # å›¾åƒå°ºå¯¸
    'batch': 8,             # æ‰¹æ¬¡å¤§å°
    'conf': 0.25,           # ç½®ä¿¡åº¦é˜ˆå€¼
    'iou': 0.5,             # NMS IoU é˜ˆå€¼
    'max_det': 300,         # æ¯å¼ å›¾æœ€å¤§æ£€æµ‹æ•°
    'device': 0,            # GPU è®¾å¤‡
    'workers': 6,           # æ•°æ®åŠ è½½çº¿ç¨‹æ•°
    'save_json': True,      # ä¿å­˜ JSON ç»“æœ
    'save_hybrid': False,   # ä¿å­˜æ··åˆæ ‡ç­¾
    'verbose': True,        # è¯¦ç»†è¾“å‡º
    'plots': True,          # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
}

# è¾“å‡ºé…ç½®
OUTPUT_DIR = Path('validation_results')
TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')

# ============================================================
# éªŒè¯ä»£ç 
# ============================================================

def validate_on_dataset(model, dataset_name, data_yaml, split='val'):
    """
    åœ¨æŒ‡å®šæ•°æ®é›†ä¸ŠéªŒè¯æ¨¡å‹
    
    Args:
        model: YOLO æ¨¡å‹å®ä¾‹
        dataset_name: æ•°æ®é›†åç§°ï¼ˆç”¨äºä¿å­˜ç»“æœï¼‰
        data_yaml: æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„
        split: éªŒè¯çš„æ•°æ®é›†åˆ†å‰² ('train', 'val', 'test')
    """
    print(f"\n{'='*60}")
    print(f"ğŸ“Š éªŒè¯æ•°æ®é›†: {dataset_name} ({split})")
    print(f"{'='*60}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_subdir = OUTPUT_DIR / f"{dataset_name}_{split}_{TIMESTAMP}"
    output_subdir.mkdir(parents=True, exist_ok=True)
    
    # è¿è¡ŒéªŒè¯
    results = model.val(
        data=data_yaml,
        split=split,              # æŒ‡å®šæ•°æ®é›†åˆ†å‰²
        project=str(output_subdir.parent),
        name=output_subdir.name,
        exist_ok=True,
        **VAL_ARGS
    )
    
    # æå–å…³é”®æŒ‡æ ‡
    # è·å–å›¾ç‰‡æ•°é‡ï¼ˆä»resultså¯¹è±¡æˆ–æ•°æ®é›†è·¯å¾„ä¸­è·å–ï¼‰
    num_images = 0
    
    # æ–¹æ³•1: ä» results.speed å­—å…¸ä¸­è·å–
    if hasattr(results, 'speed') and isinstance(results.speed, dict):
        if 'images' in results.speed:
            num_images = results.speed['images']
    
    # æ–¹æ³•2: ä» results å¯¹è±¡çš„å…¶ä»–å±æ€§å°è¯•
    if num_images == 0:
        if hasattr(results, 'seen'):
            num_images = results.seen
        elif hasattr(results.box, 'nc'):
            # å°è¯•ä»æ•°æ®é›†è·¯å¾„ç›´æ¥è¯»å–
            data_path = Path(data_yaml).parent
            if split == 'train':
                img_dir = data_path / 'train' / 'images'
            elif split == 'val':
                img_dir = data_path / 'valid' / 'images'
            else:
                img_dir = data_path / split / 'images'
            
            if img_dir.exists():
                num_images = len(list(img_dir.glob('*.jpg')) + list(img_dir.glob('*.png')) + 
                                list(img_dir.glob('*.jpeg')) + list(img_dir.glob('*.JPG')))
    
    metrics = {
        'dataset': dataset_name,
        'split': split,
        'model': str(MODEL_PATH),
        'timestamp': TIMESTAMP,
        'images': num_images,
        'metrics': {
            'mAP50': float(results.box.map50),
            'mAP50-95': float(results.box.map),
            'precision': float(results.box.mp),
            'recall': float(results.box.mr),
        },
        'per_class': {}
    }
    
    # æ¯ä¸ªç±»åˆ«çš„æŒ‡æ ‡
    if hasattr(results.box, 'ap_class_index') and results.box.ap_class_index is not None:
        for i, class_idx in enumerate(results.box.ap_class_index):
            class_name = model.names[int(class_idx)]
            metrics['per_class'][class_name] = {
                'AP50': float(results.box.ap50[i]),
                'AP': float(results.box.ap[i]),
            }
    
    # æ‰“å°ç»“æœ
    print(f"\nğŸ“ˆ éªŒè¯ç»“æœ:")
    print(f"  å›¾ç‰‡æ•°é‡: {metrics['images']}")
    print(f"  mAP50:    {metrics['metrics']['mAP50']:.3f}")
    print(f"  mAP50-95: {metrics['metrics']['mAP50-95']:.3f}")
    print(f"  Precision: {metrics['metrics']['precision']:.3f}")
    print(f"  Recall:    {metrics['metrics']['recall']:.3f}")
    
    if metrics['per_class']:
        print(f"\n  æ¯ç±»åˆ« AP50:")
        for class_name, class_metrics in metrics['per_class'].items():
            print(f"    {class_name:12s}: {class_metrics['AP50']:.3f}")
    
    print(f"\nğŸ’¾ ç»“æœä¿å­˜åˆ°: {output_subdir}/")
    
    return metrics


def validate_on_splits(model, data_yaml, dataset_name='dataset'):
    """
    åœ¨åŒä¸€æ•°æ®é›†çš„ä¸åŒåˆ†å‰²ä¸ŠéªŒè¯ï¼ˆtrain, val, testï¼‰
    
    Args:
        model: YOLO æ¨¡å‹å®ä¾‹
        data_yaml: æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„
        dataset_name: æ•°æ®é›†åç§°
    """
    all_metrics = []
    
    # éªŒè¯ä¸åŒåˆ†å‰²
    for split in ['val', 'train']:  # é€šå¸¸æœ‰ train å’Œ valï¼Œtest è§†æƒ…å†µè€Œå®š
        try:
            metrics = validate_on_dataset(model, dataset_name, data_yaml, split)
            all_metrics.append(metrics)
        except Exception as e:
            print(f"âš ï¸  éªŒè¯ {split} åˆ†å‰²å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    return all_metrics


def main():
    """ä¸»å‡½æ•°ï¼šåŠ è½½æ¨¡å‹å¹¶åœ¨æ‰€æœ‰æ•°æ®é›†ä¸ŠéªŒè¯"""
    print(f"{'='*60}")
    print(f"ğŸš€ YOLO æ¨¡å‹éªŒè¯")
    print(f"{'='*60}")
    print(f"ğŸ“¦ æ¨¡å‹: {MODEL_PATH}")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {OUTPUT_DIR}/")
    print(f"{'='*60}\n")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ”§ åŠ è½½æ¨¡å‹...")
    model = YOLO(MODEL_PATH)
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    print(f"   æ¨¡å‹ç±»å‹: {model.model.__class__.__name__}")
    print(f"   ç±»åˆ«æ•°é‡: {len(model.names)}")
    print(f"   ç±»åˆ«: {model.names}\n")
    
    # åœ¨æ‰€æœ‰æ•°æ®é›†ä¸ŠéªŒè¯
    all_results = []
    
    # æ–¹å¼1: åœ¨å¤šä¸ªæ•°æ®é›†/åˆ†å‰²ä¸ŠéªŒè¯
    for dataset_name, data_yaml in DATASETS.items():
        print(f"\n{'='*60}")
        print(f"ğŸ”„ å¤„ç†æ•°æ®é›†: {dataset_name}")
        print(f"{'='*60}")
        
        try:
            # æ ¹æ® dataset_name åˆ¤æ–­æ˜¯éªŒè¯å“ªä¸ªåˆ†å‰²
            if dataset_name in ['train', 'val', 'test']:
                split = dataset_name
                actual_name = Path(data_yaml).parent.name
            else:
                split = 'val'
                actual_name = dataset_name
            
            metrics = validate_on_dataset(model, actual_name, data_yaml, split=split)
            all_results.append(metrics)
        except Exception as e:
            print(f"âŒ éªŒè¯å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # æ–¹å¼2: åœ¨åŒä¸€æ•°æ®é›†çš„ä¸åŒåˆ†å‰²ä¸ŠéªŒè¯ï¼ˆå¯é€‰ï¼‰
    # å–æ¶ˆæ³¨é‡Šä¸‹é¢çš„ä»£ç æ¥åŒæ—¶åœ¨ train å’Œ val ä¸ŠéªŒè¯
    # print(f"\n{'='*60}")
    # print(f"ğŸ”„ åœ¨æ‰€æœ‰æ•°æ®åˆ†å‰²ä¸ŠéªŒè¯")
    # print(f"{'='*60}")
    # split_results = validate_on_splits(model, './datasets/data.yaml', 'seedTrueLeaf')
    # all_results.extend(split_results)
    
    # ä¿å­˜æ±‡æ€»ç»“æœ
    summary_file = OUTPUT_DIR / f"validation_summary_{TIMESTAMP}.json"
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)
    print(f"\nğŸ“Š æ±‡æ€»ç»“æœä¿å­˜åˆ°: {summary_file}")
    
    # åˆ›å»ºæ±‡æ€»è¡¨æ ¼
    if all_results:
        df_data = []
        for result in all_results:
            row = {
                'æ•°æ®é›†': result['dataset'],
                'åˆ†å‰²': result['split'],
                'å›¾ç‰‡æ•°': result['images'],
                'mAP50': f"{result['metrics']['mAP50']:.3f}",
                'mAP50-95': f"{result['metrics']['mAP50-95']:.3f}",
                'Precision': f"{result['metrics']['precision']:.3f}",
                'Recall': f"{result['metrics']['recall']:.3f}",
            }
            df_data.append(row)
        
        df = pd.DataFrame(df_data)
        csv_file = OUTPUT_DIR / f"validation_summary_{TIMESTAMP}.csv"
        df.to_csv(csv_file, index=False, encoding='utf-8-sig')
        
        print(f"\nğŸ“‹ æ±‡æ€»è¡¨æ ¼:")
        print(df.to_string(index=False))
        print(f"\nğŸ’¾ CSV ä¿å­˜åˆ°: {csv_file}")
    
    print(f"\n{'='*60}")
    print(f"ğŸ‰ æ‰€æœ‰éªŒè¯å®Œæˆï¼")
    print(f"{'='*60}")


if __name__ == '__main__':
    main()
