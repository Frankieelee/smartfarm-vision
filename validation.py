"""
YOLO å®Œæ•´éªŒè¯è„šæœ¬ - è·å–æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡

åŠŸèƒ½ï¼š
1. æ ‡å‡† YOLO éªŒè¯ï¼ˆmAP@0.5, mAP@0.5-0.95ï¼‰
2. å¤š IoU é˜ˆå€¼è‡ªå®šä¹‰ mAPï¼ˆmAP@0.3, mAP@0.4, mAP@0.6, mAP@0.75ï¼‰
3. æ¯ç±»åˆ«è¯¦ç»† AP
4. å®Œæ•´å¯¹æ¯”è¡¨æ ¼å’Œç»“æœä¿å­˜

ä½¿ç”¨æ–¹æ³•ï¼š
    python validation_complete.py
"""

from ultralytics import YOLO
from pathlib import Path
import numpy as np
import json
import pandas as pd
from datetime import datetime
import yaml
import torch

# ğŸ”‘ å…³é”®ï¼šç›´æ¥å¯¼å…¥ YOLO å†…éƒ¨çš„ AP è®¡ç®—å‡½æ•°
from ultralytics.utils.metrics import ap_per_class, box_iou


# ============================================================================
# é…ç½®åŒºåŸŸ
# ============================================================================

# æ¨¡å‹é…ç½®
MODEL_PATH = '/tmp/dataset/yolo11s-0.8-1.pt'

# æ•°æ®é›†é…ç½®
DATA_YAML = '/tmp/dataset/yolo11/v13/data.yaml'
DATASETS = {
    'val': DATA_YAML,       # éªŒè¯é›†
    'train': DATA_YAML,     # è®­ç»ƒé›†ï¼ˆæ£€æŸ¥è¿‡æ‹Ÿåˆï¼‰
}

# å¤š IoU é˜ˆå€¼é…ç½®
IOU_THRESHOLDS = [0.3, 0.4, 0.5, 0.6, 0.75]

# éªŒè¯å‚æ•°
VAL_ARGS = {
    'imgsz': 800,           # å›¾åƒå°ºå¯¸
    'batch': 8,             # æ‰¹æ¬¡å¤§å°
    'conf': 0.25,           # ç½®ä¿¡åº¦é˜ˆå€¼
    'iou': 0.5,             # NMS IoU é˜ˆå€¼
    'max_det': 300,         # æ¯å¼ å›¾æœ€å¤§æ£€æµ‹æ•°
    'device': 0,            # GPU è®¾å¤‡
    'workers': 6,           # æ•°æ®åŠ è½½çº¿ç¨‹æ•°
    'save_json': False,     # ä¸ä¿å­˜ JSONï¼ˆé¿å…å†—ä½™ï¼‰
    'save_hybrid': False,   # ä¸ä¿å­˜æ··åˆæ ‡ç­¾
    'verbose': False,       # å®‰é™æ¨¡å¼
    'plots': False,         # ä¸ç”Ÿæˆå›¾è¡¨ï¼ˆåŠ å¿«é€Ÿåº¦ï¼‰
}

# è¾“å‡ºé…ç½®
OUTPUT_DIR = Path('validation_complete_results')
TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')


# ============================================================================
# æ ¸å¿ƒå‡½æ•°
# ============================================================================

def get_predictions_and_labels(model, data_yaml, split='val', conf_threshold=0.25, nms_iou=0.5):
    """
    è·å–é¢„æµ‹ç»“æœå’ŒçœŸå®æ ‡ç­¾ï¼ˆç”¨äºè‡ªå®šä¹‰ mAP è®¡ç®—ï¼‰
    """
    with open(data_yaml, 'r') as f:
        data = yaml.safe_load(f)
    
    data_path = Path(data_yaml).parent
    
    # ç¡®å®šæ•°æ®é›†è·¯å¾„
    if split == 'val':
        image_dir = data_path / 'valid' / 'images'
        label_dir = data_path / 'valid' / 'labels'
    elif split == 'train':
        image_dir = data_path / 'train' / 'images'
        label_dir = data_path / 'train' / 'labels'
    else:
        image_dir = data_path / split / 'images'
        label_dir = data_path / split / 'labels'
    
    # è·å–æ‰€æœ‰å›¾åƒ
    image_files = sorted(image_dir.glob('*.jpg')) + sorted(image_dir.glob('*.png'))
    
    # ä½¿ç”¨ YOLO è¿›è¡Œé¢„æµ‹
    results = model.predict(
        source=str(image_dir),
        conf=conf_threshold,
        iou=nms_iou,
        save=False,
        verbose=False
    )
    
    # æ”¶é›†é¢„æµ‹å’Œæ ‡ç­¾
    all_stats = []
    
    for result in results:
        img_id = Path(result.path).stem
        label_file = label_dir / f"{img_id}.txt"
        
        # é¢„æµ‹æ¡†
        pred_boxes = []
        pred_confs = []
        pred_classes = []
        
        if result.boxes is not None and len(result.boxes) > 0:
            boxes = result.boxes.xyxy.cpu().numpy()
            confs = result.boxes.conf.cpu().numpy()
            classes = result.boxes.cls.cpu().numpy()
            
            img_h, img_w = result.orig_shape
            
            # å½’ä¸€åŒ–åæ ‡
            for box, conf, cls in zip(boxes, confs, classes):
                norm_box = np.array([
                    box[0] / img_w, box[1] / img_h,
                    box[2] / img_w, box[3] / img_h
                ])
                pred_boxes.append(norm_box)
                pred_confs.append(conf)
                pred_classes.append(int(cls))
        
        # çœŸå®æ ‡ç­¾
        target_boxes = []
        target_classes = []
        
        if label_file.exists():
            with open(label_file, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) < 5:
                        continue
                    
                    class_id = int(parts[0])
                    x_center = float(parts[1])
                    y_center = float(parts[2])
                    width = float(parts[3])
                    height = float(parts[4])
                    
                    # è½¬æ¢ä¸º xyxy æ ¼å¼
                    x1 = x_center - width / 2
                    y1 = y_center - height / 2
                    x2 = x_center + width / 2
                    y2 = y_center + height / 2
                    
                    target_boxes.append(np.array([x1, y1, x2, y2]))
                    target_classes.append(class_id)
        
        all_stats.append({
            'pred_boxes': np.array(pred_boxes) if pred_boxes else np.empty((0, 4)),
            'pred_confs': np.array(pred_confs) if pred_confs else np.empty(0),
            'pred_classes': np.array(pred_classes) if pred_classes else np.empty(0, dtype=int),
            'target_boxes': np.array(target_boxes) if target_boxes else np.empty((0, 4)),
            'target_classes': np.array(target_classes) if target_classes else np.empty(0, dtype=int),
        })
    
    return all_stats


def compute_map_at_iou_threshold(all_stats, iou_threshold, class_names):
    """
    è®¡ç®—æŒ‡å®š IoU é˜ˆå€¼ä¸‹çš„ mAPï¼ˆä½¿ç”¨ YOLO å†…éƒ¨å‡½æ•°ï¼‰
    """
    all_pred_boxes = []
    all_pred_confs = []
    all_pred_classes = []
    all_target_classes = []
    all_tp = []
    
    for stats in all_stats:
        pred_boxes = stats['pred_boxes']
        pred_confs = stats['pred_confs']
        pred_classes = stats['pred_classes']
        target_boxes = stats['target_boxes']
        target_classes = stats['target_classes']
        
        if len(pred_boxes) == 0:
            all_target_classes.extend(target_classes)
            continue
        
        if len(target_boxes) == 0:
            all_pred_boxes.extend(pred_boxes)
            all_pred_confs.extend(pred_confs)
            all_pred_classes.extend(pred_classes)
            all_tp.extend([False] * len(pred_boxes))
            continue
        
        # è®¡ç®— IoU
        pred_boxes_tensor = torch.tensor(pred_boxes, dtype=torch.float32)
        target_boxes_tensor = torch.tensor(target_boxes, dtype=torch.float32)
        iou_matrix = box_iou(pred_boxes_tensor, target_boxes_tensor).numpy()
        
        # æ ‡è®° TP/FP
        tp_flags = np.zeros(len(pred_boxes), dtype=bool)
        matched_targets = set()
        
        sorted_indices = np.argsort(-pred_confs)
        
        for pred_idx in sorted_indices:
            pred_class = pred_classes[pred_idx]
            
            best_iou = 0
            best_target_idx = -1
            
            for target_idx in range(len(target_boxes)):
                if target_classes[target_idx] != pred_class:
                    continue
                if target_idx in matched_targets:
                    continue
                
                iou = iou_matrix[pred_idx, target_idx]
                if iou > best_iou:
                    best_iou = iou
                    best_target_idx = target_idx
            
            if best_iou >= iou_threshold and best_target_idx != -1:
                tp_flags[pred_idx] = True
                matched_targets.add(best_target_idx)
        
        all_pred_boxes.extend(pred_boxes)
        all_pred_confs.extend(pred_confs)
        all_pred_classes.extend(pred_classes)
        all_tp.extend(tp_flags)
        all_target_classes.extend(target_classes)
    
    # è½¬æ¢ä¸º numpy æ•°ç»„
    all_pred_confs = np.array(all_pred_confs)
    all_pred_classes = np.array(all_pred_classes)
    all_target_classes = np.array(all_target_classes)
    all_tp = np.array(all_tp).reshape(-1, 1)
    
    if len(all_pred_confs) == 0:
        return {
            'mAP': 0.0,
            'Precision': 0.0,
            'Recall': 0.0,
            'per_class_ap': {},
        }
    
    # ä½¿ç”¨ YOLO å†…éƒ¨å‡½æ•°è®¡ç®— AP
    tp, fp, p, r, f1, ap, unique_classes, *_ = ap_per_class(
        tp=all_tp,
        conf=all_pred_confs,
        pred_cls=all_pred_classes,
        target_cls=all_target_classes,
        plot=False,
    )
    
    mAP = ap[:, 0].mean()
    
    per_class_ap = {}
    for i, cls_id in enumerate(unique_classes):
        class_name = class_names.get(cls_id, f'class_{cls_id}')
        per_class_ap[class_name] = float(ap[i, 0])
    
    return {
        'mAP': float(mAP),
        'Precision': float(p.mean()),
        'Recall': float(r.mean()),
        'per_class_ap': per_class_ap,
    }


def validate_complete(model, dataset_name, data_yaml, split='val'):
    """
    å®Œæ•´éªŒè¯ï¼šåŒæ—¶è·å–æ ‡å‡† YOLO æŒ‡æ ‡å’Œå¤š IoU é˜ˆå€¼çš„è‡ªå®šä¹‰ mAP
    """
    print(f"\n{'='*70}")
    print(f"ğŸ“Š å®Œæ•´éªŒè¯: {dataset_name} ({split})")
    print(f"{'='*70}")
    
    # ===== æ­¥éª¤ 1: æ ‡å‡† YOLO éªŒè¯ =====
    print(f"\nğŸ”¸ æ­¥éª¤ 1/2: æ ‡å‡† YOLO éªŒè¯...")
    
    output_subdir = OUTPUT_DIR / f"{dataset_name}_{split}_{TIMESTAMP}"
    output_subdir.mkdir(parents=True, exist_ok=True)
    
    results = model.val(
        data=data_yaml,
        split=split,
        project=str(output_subdir.parent),
        name=output_subdir.name,
        exist_ok=True,
        **VAL_ARGS
    )
    
    # æå–æ ‡å‡†æŒ‡æ ‡
    standard_metrics = {
        'mAP50': float(results.box.map50),
        'mAP50-95': float(results.box.map),
        'Precision': float(results.box.mp),
        'Recall': float(results.box.mr),
    }
    
    # æ¯ç±»åˆ« AP
    per_class_standard = {}
    if hasattr(results.box, 'ap_class_index') and results.box.ap_class_index is not None:
        for i, class_idx in enumerate(results.box.ap_class_index):
            class_name = model.names[int(class_idx)]
            per_class_standard[class_name] = {
                'AP50': float(results.box.ap50[i]),
                'AP': float(results.box.ap[i]),
            }
    
    print(f"âœ… æ ‡å‡†éªŒè¯å®Œæˆ")
    print(f"   mAP@0.5:     {standard_metrics['mAP50']:.4f}")
    print(f"   mAP@0.5-0.95: {standard_metrics['mAP50-95']:.4f}")
    
    # ===== æ­¥éª¤ 2: å¤š IoU é˜ˆå€¼è‡ªå®šä¹‰ mAP =====
    print(f"\nğŸ”¸ æ­¥éª¤ 2/2: å¤š IoU é˜ˆå€¼è‡ªå®šä¹‰ mAP...")
    print(f"   æ­£åœ¨ç”Ÿæˆé¢„æµ‹å’ŒåŠ è½½æ ‡ç­¾...")
    
    all_stats = get_predictions_and_labels(
        model, 
        data_yaml, 
        split=split,
        conf_threshold=VAL_ARGS['conf'],
        nms_iou=VAL_ARGS['iou']
    )
    
    print(f"   æ­£åœ¨è®¡ç®— mAP@{IOU_THRESHOLDS}...")
    
    # åŠ è½½ç±»åˆ«åç§°
    with open(data_yaml, 'r') as f:
        data_config = yaml.safe_load(f)
    class_names = {i: name for i, name in enumerate(data_config['names'])}
    
    # è®¡ç®—æ¯ä¸ª IoU é˜ˆå€¼çš„ mAP
    custom_metrics = {}
    for iou_threshold in IOU_THRESHOLDS:
        metrics = compute_map_at_iou_threshold(all_stats, iou_threshold, class_names)
        custom_metrics[iou_threshold] = metrics
    
    print(f"âœ… è‡ªå®šä¹‰ mAP è®¡ç®—å®Œæˆ")
    
    # ===== åˆå¹¶ç»“æœ =====
    complete_result = {
        'dataset': dataset_name,
        'split': split,
        'model': str(MODEL_PATH),
        'timestamp': TIMESTAMP,
        'standard_metrics': standard_metrics,
        'per_class_standard': per_class_standard,
        'custom_iou_metrics': custom_metrics,
    }
    
    # æ‰“å°å®Œæ•´ç»“æœ
    print(f"\n{'â”€'*70}")
    print(f"ğŸ“ˆ å®Œæ•´éªŒè¯ç»“æœæ€»ç»“")
    print(f"{'â”€'*70}")
    
    print(f"\nğŸ”¹ æ ‡å‡† YOLO æŒ‡æ ‡:")
    print(f"   mAP@0.5:      {standard_metrics['mAP50']:.4f} ({standard_metrics['mAP50']*100:.2f}%)")
    print(f"   mAP@0.5-0.95: {standard_metrics['mAP50-95']:.4f} ({standard_metrics['mAP50-95']*100:.2f}%)")
    print(f"   Precision:    {standard_metrics['Precision']:.4f} ({standard_metrics['Precision']*100:.2f}%)")
    print(f"   Recall:       {standard_metrics['Recall']:.4f} ({standard_metrics['Recall']*100:.2f}%)")
    
    print(f"\nğŸ”¹ å¤š IoU é˜ˆå€¼ mAP:")
    for iou_threshold in IOU_THRESHOLDS:
        metrics = custom_metrics[iou_threshold]
        print(f"   mAP@{iou_threshold}:      {metrics['mAP']:.4f} ({metrics['mAP']*100:.2f}%)")
    
    if per_class_standard:
        print(f"\nğŸ”¹ æ¯ç±»åˆ« AP@0.5:")
        for class_name, class_metrics in per_class_standard.items():
            print(f"   {class_name:12s}: {class_metrics['AP50']:.4f}")
    
    return complete_result


def main():
    """ä¸»å‡½æ•°"""
    print(f"{'='*70}")
    print(f"ğŸš€ YOLO å®Œæ•´éªŒè¯è„šæœ¬")
    print(f"{'='*70}")
    print(f"ğŸ“¦ æ¨¡å‹: {MODEL_PATH}")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {OUTPUT_DIR}/")
    print(f"ğŸ“ IoU é˜ˆå€¼: {IOU_THRESHOLDS}")
    print(f"{'='*70}\n")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ”§ åŠ è½½æ¨¡å‹...")
    model = YOLO(MODEL_PATH)
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    print(f"   ç±»åˆ«: {model.names}\n")
    
    # åœ¨æ‰€æœ‰æ•°æ®é›†ä¸ŠéªŒè¯
    all_results = []
    
    for dataset_name, data_yaml in DATASETS.items():
        try:
            # ç¡®å®šåˆ†å‰²
            if dataset_name in ['train', 'val', 'test']:
                split = dataset_name
                actual_name = Path(data_yaml).parent.name
            else:
                split = 'val'
                actual_name = dataset_name
            
            result = validate_complete(model, actual_name, data_yaml, split=split)
            all_results.append(result)
        except Exception as e:
            print(f"âŒ éªŒè¯å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # ===== ä¿å­˜å®Œæ•´ç»“æœ =====
    print(f"\n{'='*70}")
    print(f"ğŸ’¾ ä¿å­˜ç»“æœ...")
    print(f"{'='*70}")
    
    # JSON æ ¼å¼ï¼ˆå®Œæ•´æ•°æ®ï¼‰
    json_file = OUTPUT_DIR / f"complete_results_{TIMESTAMP}.json"
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)
    print(f"ğŸ“Š JSON ä¿å­˜åˆ°: {json_file}")
    
    # CSV æ ¼å¼ï¼ˆæ±‡æ€»è¡¨æ ¼ï¼‰
    if all_results:
        csv_data = []
        for result in all_results:
            row = {
                'æ•°æ®é›†': result['dataset'],
                'åˆ†å‰²': result['split'],
                'mAP@0.5': f"{result['standard_metrics']['mAP50']:.4f}",
                'mAP@0.5-0.95': f"{result['standard_metrics']['mAP50-95']:.4f}",
            }
            
            # æ·»åŠ å¤š IoU é˜ˆå€¼çš„ mAP
            for iou_threshold in IOU_THRESHOLDS:
                if iou_threshold in result['custom_iou_metrics']:
                    row[f'mAP@{iou_threshold}'] = f"{result['custom_iou_metrics'][iou_threshold]['mAP']:.4f}"
            
            row['Precision'] = f"{result['standard_metrics']['Precision']:.4f}"
            row['Recall'] = f"{result['standard_metrics']['Recall']:.4f}"
            
            csv_data.append(row)
        
        df = pd.DataFrame(csv_data)
        csv_file = OUTPUT_DIR / f"complete_summary_{TIMESTAMP}.csv"
        df.to_csv(csv_file, index=False, encoding='utf-8-sig')
        
        print(f"\nğŸ“‹ æ±‡æ€»è¡¨æ ¼:")
        print(df.to_string(index=False))
        print(f"\nğŸ’¾ CSV ä¿å­˜åˆ°: {csv_file}")
    
    # æ‰“å° mAP å¯¹æ¯”
    print(f"\n{'='*70}")
    print(f"ğŸ“Š mAP å¯¹æ¯”åˆ†æ")
    print(f"{'='*70}")
    
    for result in all_results:
        print(f"\nğŸ“Œ {result['dataset']} ({result['split']}):")
        
        standard_map50 = result['standard_metrics']['mAP50']
        custom_metrics = result['custom_iou_metrics']
        
        print(f"   YOLO æ ‡å‡† mAP@0.5: {standard_map50:.4f} ({standard_map50*100:.2f}%)")
        
        if 0.5 in custom_metrics:
            custom_map50 = custom_metrics[0.5]['mAP']
            diff = abs(standard_map50 - custom_map50)
            print(f"   è‡ªå®šä¹‰ mAP@0.5:    {custom_map50:.4f} ({custom_map50*100:.2f}%)")
            print(f"   å·®å¼‚:              {diff:.4f} ({diff/standard_map50*100:.2f}%) âœ“")
        
        print(f"\n   å¤š IoU é˜ˆå€¼ mAP å˜åŒ–:")
        base_map = custom_metrics.get(0.5, {}).get('mAP', 0)
        for iou_threshold in IOU_THRESHOLDS:
            if iou_threshold in custom_metrics:
                current_map = custom_metrics[iou_threshold]['mAP']
                if iou_threshold != 0.5 and base_map > 0:
                    diff = current_map - base_map
                    pct = (diff / base_map * 100)
                    symbol = "ğŸ“ˆ" if diff >= 0 else "ğŸ“‰"
                    print(f"      {symbol} mAP@{iou_threshold}: {current_map:.4f} ({pct:+.2f}%)")
                else:
                    print(f"      â€¢ mAP@{iou_threshold}: {current_map:.4f} (åŸºå‡†)")
    
    print(f"\n{'='*70}")
    print(f"ğŸ‰ æ‰€æœ‰éªŒè¯å®Œæˆï¼")
    print(f"{'='*70}")


if __name__ == '__main__':
    main()
